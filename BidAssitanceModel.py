"""Bid Assistance RAG Pipeline (LangGraph)

ê³µê³ ë¬¸ -> LLM ì¶”ì¶œ -> ToolNode(RAG+ë‚™ì°°ê°€ì˜ˆì¸¡+ê²½ìŸ) -> LLM ë¦¬í¬íŠ¸

ìš”êµ¬ íŒŒì¼/ì•„í‹°íŒ©íŠ¸
-----------------
- model_1dcnn.py (ì‚¬ìš©ì ì—…ë¡œë“œ ì½”ë“œ)
- best_model.pt (í•™ìŠµ ì½”ë“œì—ì„œ ì €ì¥ë˜ëŠ” state_dict)
- scalers.json ë˜ëŠ” scalers.npz (í•„ìˆ˜ ê¶Œì¥: X/y ìŠ¤ì¼€ì¼ëŸ¬ + target_log ì„¤ì •)

ì˜ì¡´ì„±
------
pip install langgraph langchain-core langchain-openai langchain-community langchain-text-splitters pydantic faiss-cpu openai
# PDF ì…ë ¥ì„ ì“°ë©´(ë‘˜ ì¤‘ í•˜ë‚˜ ê¶Œì¥):
#   pip install pypdf
#   pip install pymupdf
# CNN1D ëª¨ë¸ì„ ì“°ë©´ ì¶”ê°€:
pip install torch numpy pandas matplotlib

í™˜ê²½ë³€ìˆ˜
--------
OPENAI_API_KEY ì„¤ì •(ê¶Œì¥) ë˜ëŠ” api_key.txtì— KEY=VALUE í˜•ì‹ìœ¼ë¡œ ì €ì¥.

CLI ì‚¬ìš©
--------
python BidAssitanceModel_fixed_pdf.py \
  --doc_dir ./rag_corpus \
  --index_dir ./rag_index \
  --input bid_notice.txt \
  --award_model ./model_1dcnn.py \
  --award_weights ./results/best_model.pt \
  --award_scaler ./results/scalers.json

ì£¼ì˜
----
- scalers.json(.npz)ê°€ ì—†ìœ¼ë©´, CNN1D ëª¨ë¸ì€ ì˜¬ë°”ë¥¸ ì—­ë³€í™˜ì´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ
  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  low-confidenceë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import inspect
import importlib.util
import json
import os
import re
from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, TypedDict, Annotated
import zipfile
import xml.etree.ElementTree as ET
import zlib
import olefile

from pydantic import BaseModel, Field

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.tools import tool

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages

# ------------------------------
# Utilities
# ------------------------------

def load_api_keys(filepath: str = "api_key.txt") -> None:
    """Load KEY=VALUE lines into os.environ (optional)."""
    if not os.path.exists(filepath):
        return
    with open(filepath, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or "=" not in line:
                continue
            key, value = line.split("=", 1)
            os.environ[key.strip()] = value.strip()


def _parse_number(value: Any) -> Optional[float]:
    """Parse numeric values robustly (handles commas, 'ì›', '%', etc.)."""
    if value is None:
        return None
    if isinstance(value, (int, float)):
        try:
            return float(value)
        except Exception:
            return None

    s = str(value).strip()
    if not s:
        return None

    # Remove common separators/units
    s = s.replace(",", "")
    s = s.replace("ì›", "").replace("KRW", "").replace("â‚©", "")
    s = s.replace("%", "")
    # Keep digits / dot / minus only
    s = re.sub(r"[^0-9\.\-]", "", s)
    if not s or s in ("-", ".", "-."):
        return None
    try:
        return float(s)
    except Exception:
        return None


def _clean_whitespace(text: str) -> str:
    return re.sub(r"\s+", " ", str(text)).strip()


def _load_module_from_py(py_path: str):
    """Dynamically load a python module from a file path."""
    if not os.path.exists(py_path):
        raise FileNotFoundError(f"Python file not found: {py_path}")

    mod_name = f"user_mod_{abs(hash(os.path.abspath(py_path)))}"
    spec = importlib.util.spec_from_file_location(mod_name, py_path)
    if spec is None or spec.loader is None:
        raise RuntimeError(f"Failed to load python module spec: {py_path}")

    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)  # type: ignore[attr-defined]
    return module




def extract_text_from_hwp(hwp_path: str) -> str:
    try:
        f = olefile.OleFileIO(hwp_path)
        dirs = f.listdir()
        bodytext_dirs = [d for d in dirs if d[0].startswith('BodyText')]
        full_text = []
        for d in bodytext_dirs:
            section = f.openstream(d).read()
            try:
                # HWP V5.0 ì´ìƒì€ zlib ì••ì¶•ì„ ì‚¬ìš©í•¨
                decompressed = zlib.decompress(section, -15)
                text = decompressed.decode('utf-16', errors='ignore')
                full_text.append(text)
            except:
                continue
        return "\n".join(full_text)
    except Exception as e:
        print(f"âŒ HWP ì¶”ì¶œ ì—ëŸ¬: {e}")
        return ""

def extract_text_from_hwpx(hwpx_path: str) -> str:
    try:
        with zipfile.ZipFile(hwpx_path, 'r') as zf:
            content_files = [f for f in zf.namelist() if f.startswith('Contents/section') and f.endswith('.xml')]
            full_text = []
            for file in content_files:
                with zf.open(file) as f:
                    tree = ET.parse(f)
                    root = tree.getroot()
                    for t in root.iter():
                        if t.tag.endswith('t') and t.text:
                            full_text.append(t.text)
            return "\n".join(full_text)
    except Exception as e:
        print(f"âŒ HWPX ì¶”ì¶œ ì—ëŸ¬: {e}")
        return ""

def extract_text_from_pdf(pdf_path: str) -> str:
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    text = ""
    try:
        from pypdf import PdfReader
        reader = PdfReader(pdf_path)
        parts = []
        for page in reader.pages:
            try: parts.append(page.extract_text() or "")
            except: parts.append("")
        text = "\n\n".join(parts)
    except:
        text = ""
    if len(_clean_whitespace(text)) < 50:
        try:
            import fitz
            doc = fitz.open(pdf_path)
            parts = []
            for page in doc:
                try: parts.append(page.get_text("text") or "")
                except: parts.append("")
            doc.close()
            text = "\n\n".join(parts)
        except:
            pass
    text = text.replace("\x00", " ")
    return text

def read_input_text(input_path: str) -> str:
    ext = os.path.splitext(input_path)[1].lower()
    if ext == ".pdf":
        return extract_text_from_pdf(input_path)
    with open(input_path, "r", encoding="utf-8", errors="ignore") as f:
        return f.read()


def _callable_looks_like_wrapper(fn: Callable[..., Any]) -> bool:
    """Heuristic: wrapper predict function should accept exactly 2 positional args."""
    try:
        sig = inspect.signature(fn)
    except Exception:
        return False

    params = list(sig.parameters.values())
    # count required positional-or-keyword params without defaults
    required = [
        p for p in params
        if p.kind in (p.POSITIONAL_ONLY, p.POSITIONAL_OR_KEYWORD) and p.default is p.empty
    ]
    # We want at least 2 (requirements, retrieved_context), and allow extra optional params
    return len(required) == 2


def _coerce_percent(v: Optional[float]) -> Optional[float]:
    """If v looks like 0~1 ratio, convert to 0~100 percent."""
    if v is None:
        return None
    if 0 < v <= 1.5:
        return v * 100.0
    return v


# ------------------------------
# Award-price predictor adapters
# ------------------------------

class AwardPricePredictor:
    """Interface so ToolNode can call the winning-price predictor safely."""
    def predict(self, requirements: Dict[str, Any], retrieved_context: str) -> Dict[str, Any]:
        raise NotImplementedError


class HeuristicAwardPricePredictor(AwardPricePredictor):
    """Fallback baseline when a user model is not wired yet."""

    def predict(self, requirements: Dict[str, Any], retrieved_context: str) -> Dict[str, Any]:
        budget = _parse_number(requirements.get("budget"))
        estimate = _parse_number(requirements.get("estimate_price"))
        base = estimate if estimate is not None else budget

        if base is None or base <= 0:
            return {
                "currency": "KRW",
                "predicted_min": None,
                "predicted_max": None,
                "point_estimate": None,
                "confidence": "low",
                "rationale": [
                    "ê³µê³ ë¬¸ì—ì„œ ì˜ˆì‚°/ì¶”ì •ê°€ê²©ì„ í™•ì •ì ìœ¼ë¡œ íŒŒì•…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    "ë‚™ì°°ê°€ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ê³µê³ ì˜ ê¸°ì´ˆê¸ˆì•¡/ì¶”ì •ê°€ê²© ë“± í•µì‹¬ ìˆ«ì í•„ë“œë¥¼ ë³´ì™„í•´ì•¼ í•©ë‹ˆë‹¤.",
                ],
                "model": {"type": "heuristic", "name": "baseline_band"},
            }

        strictness = 0
        strictness += 1 if len(requirements.get("qualification_requirements", [])) >= 5 else 0
        strictness += 1 if len(requirements.get("performance_requirements", [])) >= 5 else 0
        strictness += 1 if any("ë³´ì¦" in str(s) for s in requirements.get("risk_flags", [])) else 0

        min_ratio = 0.90 - 0.01 * strictness
        max_ratio = 0.97 - 0.005 * strictness
        min_ratio = max(0.80, min_ratio)
        max_ratio = max(min_ratio + 0.03, max_ratio)

        pred_min = round(base * min_ratio)
        pred_max = round(base * max_ratio)
        point = round((pred_min + pred_max) / 2)

        return {
            "currency": "KRW",
            "predicted_min": pred_min,
            "predicted_max": pred_max,
            "point_estimate": point,
            "confidence": "medium" if strictness <= 1 else "low",
            "rationale": [
                "ê¸°ì´ˆê¸ˆì•¡/ì¶”ì •ê°€ê²©ì„ ê¸°ì¤€(base)ìœ¼ë¡œ ë‚™ì°°ê°€ ë°´ë“œ(ë¹„ìœ¨) ì¶”ì •(íœ´ë¦¬ìŠ¤í‹±)ì…ë‹ˆë‹¤.",
                "ì •í™•í•œ ì˜ˆì¸¡ì€ ë‚™ì°°ê°€ ì˜ˆì¸¡ ëª¨ë¸ë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤.",
            ],
            "used_base": base,
            "used_band": {"min_ratio": min_ratio, "max_ratio": max_ratio},
            "model": {"type": "heuristic", "name": "baseline_band"},
        }


class CallableAwardPricePredictor(AwardPricePredictor):
    def __init__(self, predict_fn: Callable[[Dict[str, Any], str], Any], model_info: Optional[Dict[str, Any]] = None):
        self.predict_fn = predict_fn
        self.model_info = model_info or {"type": "callable"}

    def predict(self, requirements: Dict[str, Any], retrieved_context: str) -> Dict[str, Any]:
        try:
            out = self.predict_fn(requirements, retrieved_context)
        except Exception as e:
            return {
                "currency": "KRW",
                "predicted_min": None,
                "predicted_max": None,
                "point_estimate": None,
                "confidence": "low",
                "rationale": [
                    "ì‚¬ìš©ì ë‚™ì°°ê°€ ì˜ˆì¸¡ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    f"ì˜ˆì™¸: {type(e).__name__}: {str(e)}",
                ],
                "model": self.model_info,
            }

        if isinstance(out, (int, float)):
            return {
                "currency": "KRW",
                "point_estimate": float(out),
                "predicted_min": None,
                "predicted_max": None,
                "confidence": "medium",
                "rationale": ["ì‚¬ìš©ì ëª¨ë¸ì´ ë‹¨ì¼ ë‚™ì°°ê°€ ì˜ˆì¸¡ê°’(í¬ì¸íŠ¸)ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."],
                "model": self.model_info,
            }
        if isinstance(out, dict):
            out.setdefault("model", self.model_info)
            return out

        return {
            "currency": "KRW",
            "predicted_min": None,
            "predicted_max": None,
            "point_estimate": None,
            "confidence": "low",
            "rationale": ["ì‚¬ìš©ì ëª¨ë¸ ì¶œë ¥ í˜•ì‹ì´ ì˜ˆìƒ(dict/ìˆ«ì)ê³¼ ë‹¬ë¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."],
            "model": self.model_info,
        }

class TFTPredictorWrapper(AwardPricePredictor):
    """
    TFT ëª¨ë¸ ì „ìš© ë˜í¼ - top_rangesë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬

    RAG_server.pyì˜ TFTPredictorAdapter ê°ì²´ë¥¼ ë°›ì•„ì„œ ë˜í•‘í•©ë‹ˆë‹¤.
    ì˜ˆì¸¡ ê²°ê³¼ì˜ top_rangesë¥¼ ë‚´ë¶€ì— ì €ì¥í•˜ì—¬ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
    """

    def __init__(self, adapter):
        """
        Args:
            adapter: TFTPredictorAdapter ì¸ìŠ¤í„´ìŠ¤
        """
        self.adapter = adapter
        self.top_ranges = None  # ë§ˆì§€ë§‰ ì˜ˆì¸¡ì˜ top_ranges ì €ì¥
        self.last_prediction = None  # ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥

    def predict(self, requirements: Dict[str, Any], retrieved_context: str) -> Dict[str, Any]:
        """
        TFT ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ ë° ê²°ê³¼ ì €ì¥

        Returns:
            Dict containing:
                - point_estimate: ê°€ì¥ í™•ë¥  ë†’ì€ ì˜ˆì¸¡ê°’
                - top_ranges: í™•ë¥  ë†’ì€ ìƒìœ„ êµ¬ê°„ë“¤ (List)
                - statistics: í†µê³„ ì •ë³´ (mean, median, q25, q75 ë“±)
                - confidence, rationale, model_type ë“±
        """
        try:
            # TFTPredictorAdapterì˜ predict() í˜¸ì¶œ
            result = self.adapter.predict(requirements, retrieved_context)

            # ê²°ê³¼ ì €ì¥
            self.last_prediction = result

            # top_ranges ëª…ì‹œì  ì €ì¥
            if isinstance(result, dict) and "top_ranges" in result:
                self.top_ranges = result["top_ranges"]
                print(f"âœ… TFT ì˜ˆì¸¡ ì™„ë£Œ - top_ranges ì €ì¥: {len(self.top_ranges)}ê°œ êµ¬ê°„")
                print(f"   ìµœê³  í™•ë¥  êµ¬ê°„ ì¤‘ì‹¬ê°’: {self.top_ranges[0]['center']:,.0f}ì›")
            else:
                self.top_ranges = None
                print("âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ì— top_rangesê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            return result

        except Exception as e:
            print(f"âŒ TFT ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            self.last_prediction = None
            self.top_ranges = None

            return {
                "currency": "KRW",
                "point_estimate": 0,
                "predicted_min": 0,
                "predicted_max": 0,
                "confidence": "error",
                "rationale": f"TFT ëª¨ë¸ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "model_type": "TFT (error)",
                "error": str(e)
            }

    def get_top_ranges(self) -> Optional[List[Dict[str, Any]]]:
        """ì €ì¥ëœ top_ranges ë°˜í™˜"""
        return self.top_ranges

    def get_last_prediction(self) -> Optional[Dict[str, Any]]:
        """ë§ˆì§€ë§‰ ì˜ˆì¸¡ ê²°ê³¼ ì „ì²´ ë°˜í™˜"""
        return self.last_prediction


class CNN1DAwardPricePredictor(AwardPricePredictor):
    """Auto-adapter for model_1dcnn.py (1D CNN + scalers + log target)."""

    def __init__(
        self,
        module: Any,
        weights_path: str,
        scaler_path: Optional[str] = None,
        device: Optional[str] = None,
        hidden: int = 64,
        dropout: float = 0.1,
    ):
        self.module = module
        self.weights_path = weights_path
        self.scaler_path = scaler_path
        self.device = device
        self.hidden = hidden
        self.dropout = dropout

        self._torch = self._import_torch()
        self._np = self._import_numpy()

        if self.device is None:
            self.device = "cuda" if self._torch.cuda.is_available() else "cpu"

        self.model = self.module.CNN1DRegressor(hidden=self.hidden, dropout=self.dropout).to(self.device)
        self._load_weights()

        self.x_scaler = None
        self.y_scaler = None
        self.target_log = True
        self.feature_cols = ["ê¸°ì´ˆê¸ˆì•¡", "ì¶”ì •ê°€ê²©", "ì˜ˆê°€ë²”ìœ„", "ë‚™ì°°í•˜í•œìœ¨"]

        self._load_scalers()

    def _import_torch(self):
        try:
            import torch  # type: ignore
            return torch
        except Exception as e:
            raise RuntimeError(
                "PyTorch(torch)ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
                "CNN1D ë‚™ì°°ê°€ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ torchê°€ í•„ìš”í•©ë‹ˆë‹¤."
            ) from e

    def _import_numpy(self):
        try:
            import numpy as np  # type: ignore
            return np
        except Exception as e:
            raise RuntimeError("numpyê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from e

    def _load_weights(self) -> None:
        if not os.path.exists(self.weights_path):
            raise FileNotFoundError(f"ë‚™ì°°ê°€ ëª¨ë¸ ê°€ì¤‘ì¹˜(.pt) íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.weights_path}")
        state = self._torch.load(self.weights_path, map_location=self.device)
        if isinstance(state, dict) and all(isinstance(k, str) for k in state.keys()):
            self.model.load_state_dict(state)
        elif isinstance(state, dict) and "state_dict" in state and isinstance(state["state_dict"], dict):
            self.model.load_state_dict(state["state_dict"])
        else:
            raise ValueError("ê°€ì¤‘ì¹˜ í¬ë§·ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. state_dict(dict) í˜•íƒœë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.")
        self.model.eval()

    def _load_scalers(self) -> None:
        if not self.scaler_path:
            base_dir = os.path.dirname(self.weights_path) or "."
            c_json = os.path.join(base_dir, "scalers.json")
            c_npz = os.path.join(base_dir, "scalers.npz")
            if os.path.exists(c_json):
                self.scaler_path = c_json
            elif os.path.exists(c_npz):
                self.scaler_path = c_npz

        if not self.scaler_path or not os.path.exists(self.scaler_path):
            return

        x_mean = None
        x_std = None
        y_mean = None
        y_std = None
        feature_cols = None
        target_log = None

        if self.scaler_path.lower().endswith(".json"):
            with open(self.scaler_path, "r", encoding="utf-8") as f:
                cfg = json.load(f)
            x_mean = cfg.get("x_mean")
            x_std = cfg.get("x_std")
            y_mean = cfg.get("y_mean")
            y_std = cfg.get("y_std")
            feature_cols = cfg.get("feature_cols")
            target_log = cfg.get("target_log")
        elif self.scaler_path.lower().endswith(".npz"):
            arr = self._np.load(self.scaler_path, allow_pickle=True)
            x_mean = arr.get("x_mean")
            x_std = arr.get("x_std")
            y_mean = arr.get("y_mean")
            y_std = arr.get("y_std")
            feature_cols = arr.get("feature_cols")
            target_log = arr.get("target_log")
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ í™•ì¥ìì…ë‹ˆë‹¤. .json ë˜ëŠ” .npzë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

        if x_mean is None or x_std is None or y_mean is None or y_std is None:
            raise ValueError("scaler íŒŒì¼ì— x_mean/x_std/y_mean/y_std ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")

        self.x_scaler = self.module.StandardScaler()
        self.x_scaler.mean_ = self._np.asarray(x_mean, dtype=self._np.float32)
        self.x_scaler.std_ = self._np.asarray(x_std, dtype=self._np.float32)

        self.y_scaler = self.module.TargetScaler()
        self.y_scaler.mean_ = float(self._np.asarray(y_mean).reshape(-1)[0])
        self.y_scaler.std_ = float(self._np.asarray(y_std).reshape(-1)[0])

        if feature_cols is not None:
            if isinstance(feature_cols, (list, tuple)):
                self.feature_cols = [str(x) for x in feature_cols]
            else:
                # e.g. numpy array
                try:
                    self.feature_cols = [str(x) for x in list(feature_cols)]
                except Exception:
                    pass

        if target_log is not None:
            self.target_log = bool(target_log)

    def _extract_feature(
        self,
        requirements: Dict[str, Any],
        retrieved_context: str,
        keys: Sequence[str],
        patterns: Sequence[str],
    ) -> Optional[float]:
        for k in keys:
            v = _parse_number(requirements.get(k))
            if v is not None:
                return v

        text = retrieved_context or ""
        for pat in patterns:
            m = re.search(pat, text)
            if m:
                v = _parse_number(m.group(1))
                if v is not None:
                    return v
        return None

    def _build_feature_vector(self, requirements: Dict[str, Any], retrieved_context: str) -> Tuple[Optional[Any], List[str]]:
        missing: List[str] = []

        base_amount = self._extract_feature(
            requirements,
            retrieved_context,
            keys=["budget", "base_amount", "ê¸°ì´ˆê¸ˆì•¡"],
            patterns=[
                r"ê¸°ì´ˆ\s*ê¸ˆì•¡\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)",
                r"ê¸°ì´ˆê¸ˆì•¡\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)",
            ],
        )
        if base_amount is None:
            missing.append("ê¸°ì´ˆê¸ˆì•¡(budget)")

        estimate_price = self._extract_feature(
            requirements,
            retrieved_context,
            keys=["estimate_price", "ì¶”ì •ê°€ê²©", "ì˜ˆì •ê°€ê²©"],
            patterns=[
                r"ì¶”ì •\s*ê°€ê²©\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)",
                r"ì˜ˆì •\s*ê°€ê²©\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)",
            ],
        )
        if estimate_price is None:
            missing.append("ì¶”ì •ê°€ê²©(estimate_price)")

        price_range = self._extract_feature(
            requirements,
            retrieved_context,
            keys=["expected_price_range", "ì˜ˆê°€ë²”ìœ„"],
            patterns=[
                r"ì˜ˆê°€\s*ë²”ìœ„\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)\s*%?",
                r"ì˜ˆê°€ë²”ìœ„\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)\s*%?",
            ],
        )
        price_range = _coerce_percent(price_range)
        if price_range is None:
            missing.append("ì˜ˆê°€ë²”ìœ„(expected_price_range)")

        lower_rate = self._extract_feature(
            requirements,
            retrieved_context,
            keys=["award_lower_rate", "ë‚™ì°°í•˜í•œìœ¨"],
            patterns=[
                r"ë‚™ì°°\s*í•˜í•œ\s*ìœ¨\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)\s*%?",
                r"ë‚™ì°°í•˜í•œìœ¨\s*[:ï¼š]?\s*([0-9][0-9,]*(?:\.[0-9]+)?)\s*%?",
            ],
        )
        lower_rate = _coerce_percent(lower_rate)
        if lower_rate is None:
            missing.append("ë‚™ì°°í•˜í•œìœ¨(award_lower_rate)")

        if missing:
            return None, missing

        x = self._np.asarray(
            [base_amount, estimate_price, price_range, lower_rate],
            dtype=self._np.float32,
        ).reshape(1, -1)
        return x, []

    def predict(self, requirements: Dict[str, Any], retrieved_context: str) -> Dict[str, Any]:
        x, missing = self._build_feature_vector(requirements, retrieved_context or "")
        if missing:
            return {
                "currency": "KRW",
                "predicted_min": None,
                "predicted_max": None,
                "point_estimate": None,
                "confidence": "low",
                "rationale": [
                    "ë‚™ì°°ê°€ ì˜ˆì¸¡ì— í•„ìš”í•œ í”¼ì²˜ë¥¼ ì¶©ë¶„íˆ í™•ë³´í•˜ì§€ ëª»í•´ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "ëˆ„ë½ í”¼ì²˜: " + ", ".join(missing),
                    "í•´ê²°: ê³µê³ ë¬¸ ì¶”ì¶œ í•„ë“œì— ì˜ˆê°€ë²”ìœ„/ë‚™ì°°í•˜í•œìœ¨ì„ í¬í•¨í•˜ê±°ë‚˜, RAG ì½”í¼ìŠ¤ì—ì„œ í•´ë‹¹ ìˆ˜ì¹˜ë¥¼ íšŒìˆ˜í•  ìˆ˜ ìˆë„ë¡ ë¬¸ì„œë¥¼ ë³´ê°•í•˜ì„¸ìš”.",
                ],
                "model": {
                    "type": "cnn1d",
                    "code": getattr(self.module, "__file__", "<module>"),
                    "weights": self.weights_path,
                    "scaler": self.scaler_path,
                    "device": self.device,
                    "hidden": self.hidden,
                    "dropout": self.dropout,
                },
            }

        if self.x_scaler is None or self.y_scaler is None:
            return {
                "currency": "KRW",
                "predicted_min": None,
                "predicted_max": None,
                "point_estimate": None,
                "confidence": "low",
                "rationale": [
                    "CNN1D ëª¨ë¸ì€ í•™ìŠµ ì‹œ X/y ìŠ¤ì¼€ì¼ë§(ë° ë¡œê·¸ ë³€í™˜)ì„ ì‚¬ìš©í–ˆìœ¼ë‚˜, scaler/config íŒŒì¼ì´ ì—†ì–´ ì˜¬ë°”ë¥¸ ì—­ë³€í™˜ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.",
                    "í•´ê²°: í•™ìŠµ ì‹œ x_mean/x_std/y_mean/y_std ë° target_logë¥¼ scalers.json(.npz)ë¡œ ì €ì¥í•˜ì„¸ìš”.",
                ],
                "model": {
                    "type": "cnn1d",
                    "code": getattr(self.module, "__file__", "<module>"),
                    "weights": self.weights_path,
                    "scaler": self.scaler_path,
                    "device": self.device,
                    "hidden": self.hidden,
                    "dropout": self.dropout,
                },
            }

        x_scaled = self.x_scaler.transform(x)  # (1,F)
        x_tensor = self._torch.from_numpy(x_scaled.astype("float32")).reshape(1, -1, 1).to(self.device)

        with self._torch.no_grad():
            y_hat_scaled = self.model(x_tensor).detach().cpu().numpy().reshape(-1)

        y_hat = self.y_scaler.inverse_transform(y_hat_scaled).reshape(-1)
        if self.target_log:
            y_hat = self._np.expm1(y_hat)

        point = float(y_hat[0])
        pred_min = round(point * 0.98)
        pred_max = round(point * 1.02)

        return {
            "currency": "KRW",
            "predicted_min": pred_min,
            "predicted_max": pred_max,
            "point_estimate": round(point),
            "confidence": "medium",
            "rationale": [
                "ì‚¬ìš©ì 1D-CNN ë‚™ì°°ê°€ ì˜ˆì¸¡ ëª¨ë¸ ì¶”ë¡  ê²°ê³¼ì…ë‹ˆë‹¤.",
                "predicted_min/maxëŠ” ë¶ˆí™•ì‹¤ë„ ì¶”ì •ì¹˜ê°€ ì•„ë‹ˆë¼, ë³´ê³ ì„œ í‘œê¸°ë¥¼ ìœ„í•œ Â±2% íœ´ë¦¬ìŠ¤í‹± ë°´ë“œì…ë‹ˆë‹¤(í•„ìš” ì‹œ êµì²´).",
                f"í”¼ì²˜ ì‚¬ìš© ìˆœì„œ: {', '.join(self.feature_cols)}",
            ],
            "model": {
                "type": "cnn1d",
                "code": getattr(self.module, "__file__", "<module>"),
                "weights": self.weights_path,
                "scaler": self.scaler_path,
                "device": self.device,
                "hidden": self.hidden,
                "dropout": self.dropout,
            },
        }


# ------------------------------
# Structured schema (extract)
# ------------------------------

class BidRequirements(BaseModel):
    """Extracted fields from bid notice."""

    title: Optional[str] = Field(None, description="ê³µê³ ëª…")
    agency: Optional[str] = Field(None, description="ë°œì£¼ê¸°ê´€/ìˆ˜ìš”ê¸°ê´€")
    category: Optional[str] = Field(None, description="ìš©ì—­/ë¬¼í’ˆ/ê³µì‚¬ ë“± êµ¬ë¶„")
    region: Optional[str] = Field(None, description="ìˆ˜í–‰ì§€ì—­/ë‚©í’ˆì§€ì—­")
    deadline: Optional[str] = Field(None, description="ë§ˆê° ì¼ì‹œ(ë¬¸ìì—´)")

    budget: Optional[float] = Field(None, description="ì˜ˆì‚°/ê¸°ì´ˆê¸ˆì•¡ (ê°€ëŠ¥í•˜ë©´ ìˆ«ì)")
    estimate_price: Optional[float] = Field(None, description="ì¶”ì •ê°€ê²©/ì˜ˆì •ê°€ê²©(ê°€ëŠ¥í•˜ë©´ ìˆ«ì)")
    expected_price_range: Optional[float] = Field(None, description="ì˜ˆê°€ë²”ìœ„(%) ë˜ëŠ” ë²”ìœ„ê°’(ê°€ëŠ¥í•˜ë©´ ìˆ«ì)")
    award_lower_rate: Optional[float] = Field(None, description="ë‚™ì°°í•˜í•œìœ¨(%) (ê°€ëŠ¥í•˜ë©´ ìˆ«ì)")

    bid_method: Optional[str] = Field(None, description="ë‚™ì°°ì ê²°ì • ë°©ì‹/í‰ê°€ ë°©ì‹")

    qualification_requirements: List[str] = Field(default_factory=list, description="ì°¸ê°€ìê²©/ë©´í—ˆ/ë“±ê¸‰/ì¸ì¦/ìš”ê±´")
    performance_requirements: List[str] = Field(default_factory=list, description="ì‹¤ì ìš”ê±´/ê²½ë ¥/ìœ ì‚¬ì‹¤ì /ìˆ˜í–‰ëŠ¥ë ¥")
    document_requirements: List[str] = Field(default_factory=list, description="ì œì¶œì„œë¥˜/ì œì•ˆì„œ/ì¦ë¹™")
    risk_flags: List[str] = Field(default_factory=list, description="íŠ¹ì´ì‚¬í•­/ë¦¬ìŠ¤í¬(ë³´ì¦ê¸ˆ, ì œì¬, í•˜ë„ê¸‰ ì œí•œ ë“±)")


# ------------------------------
# LangGraph state
# ------------------------------

class GraphState(TypedDict, total=False):
    messages: Annotated[List[Any], add_messages]
    requirements: Dict[str, Any]
    prediction_result: Dict[str, Any]  # <--- ì¶”ê°€
    report_markdown: str


# ------------------------------
# RAG index (FAISS)
# ------------------------------

class RagIndex:
    def __init__(self, doc_dir: str, index_dir: str, embedding_model: str):
        self.doc_dir = doc_dir
        self.index_dir = index_dir
        self.embedding_model = embedding_model
        self._vs: Optional[FAISS] = None

    def _load_txt_documents(self) -> List[str]:
        if not os.path.isdir(self.doc_dir):
            return []
        texts: List[str] = []
        for root, _, files in os.walk(self.doc_dir):
            for name in files:
                if not name.lower().endswith(".txt"):
                    continue
                path = os.path.join(root, name)
                with open(path, "r", encoding="utf-8", errors="ignore") as f:
                    texts.append(f.read())
        return texts

    def build_or_load(self, force_rebuild: bool = False) -> FAISS:
        embeddings = OpenAIEmbeddings(model=self.embedding_model)

        if not force_rebuild and os.path.isdir(self.index_dir):
            try:
                self._vs = FAISS.load_local(
                    self.index_dir,
                    embeddings,
                    allow_dangerous_deserialization=True,
                )
                return self._vs
            except Exception:
                pass

        texts = self._load_txt_documents()
        if not texts:
            self._vs = FAISS.from_texts([""], embeddings)
            os.makedirs(self.index_dir, exist_ok=True)
            self._vs.save_local(self.index_dir)
            return self._vs

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
        chunks: List[str] = []
        for t in texts:
            chunks.extend(splitter.split_text(t))

        self._vs = FAISS.from_texts(chunks, embeddings)
        os.makedirs(self.index_dir, exist_ok=True)
        self._vs.save_local(self.index_dir)
        return self._vs

    @property
    def vs(self) -> FAISS:
        if self._vs is None:
            raise RuntimeError("RAG index is not initialized. Call build_or_load().")
        return self._vs

    def retrieve(self, query: str, k: int = 5) -> List[str]:
        query = _clean_whitespace(query)
        if not query:
            return []
        docs = self.vs.similarity_search(query, k=k)
        return [d.page_content for d in docs if getattr(d, "page_content", None)]


# ------------------------------
# Pipeline (LangGraph)
# ------------------------------

class BidRAGPipeline:
    def __init__(
            self,
            doc_dir: str = "./rag_corpus",
            index_dir: str = "./rag_index",
            llm_model: str = "gpt-4o-mini",
            embedding_model: str = "text-embedding-3-large",
            top_k: int = 6,
            award_model_path: Optional[str] = None,
            award_weights_path: Optional[str] = None,
            award_scaler_path: Optional[str] = None,
            award_device: Optional[str] = None,
            award_hidden: int = 64,
            award_dropout: float = 0.1,
            award_predict_fn: Optional[Callable[[Dict[str, Any], str], Any]] = None,  # â˜… ì™¸ë¶€ í•¨ìˆ˜ ì£¼ì…ìš©
            award_predictor_instance: Optional[Any] = None,
    ):
        load_api_keys("api_key.txt")

        self.doc_dir = doc_dir
        self.index_dir = index_dir
        self.top_k = top_k

        self.llm = ChatOpenAI(model=llm_model, temperature=0)
        self.index = RagIndex(doc_dir=doc_dir, index_dir=index_dir, embedding_model=embedding_model)
        self.index.build_or_load(force_rebuild=False)

        # â˜… ëª¨ë¸ ì´ˆê¸°í™” ì‹œ award_predict_fnì„ ê°€ì¥ ë¨¼ì € ì²´í¬í•˜ë„ë¡ í•¨
        self.award_predictor = self._init_award_predictor(
            award_model_path=award_model_path,
            award_weights_path=award_weights_path,
            award_scaler_path=award_scaler_path,
            award_device=award_device,
            award_hidden=award_hidden,
            award_dropout=award_dropout,
            award_predict_fn=award_predict_fn,
            award_predictor_instance=award_predictor_instance,
        )

        self.graph = self._build_graph()

    def _init_award_predictor(
            self,
            award_model_path: Optional[str],
            award_weights_path: Optional[str],
            award_scaler_path: Optional[str],
            award_device: Optional[str],
            award_hidden: int,
            award_dropout: float,
            award_predict_fn: Optional[Callable[[Dict[str, Any], str], Any]],
            award_predictor_instance: Optional[Any] = None,
    ) -> AwardPricePredictor:

        if award_predictor_instance is not None:
            print("âœ… BidRAGPipeline: TFT Adapter ê°ì²´ë¡œ ì´ˆê¸°í™” (top_ranges ëª…ì‹œì  ê´€ë¦¬)")
            return TFTPredictorWrapper(award_predictor_instance)

        # â˜… [í•µì‹¬ ìˆ˜ì •] ì™¸ë¶€ì—ì„œ Transformer ì–´ëŒ‘í„° ê°™ì€ í•¨ìˆ˜ê°€ ë“¤ì–´ì˜¤ë©´ ë°”ë¡œ ë¦¬í„´!
        if award_predict_fn is not None:
            print("âœ… BidRAGPipeline: ì™¸ë¶€ì—ì„œ ì£¼ì…ëœ ì˜ˆì¸¡ í•¨ìˆ˜(Transformer ë“±)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return CallableAwardPricePredictor(
                predict_fn=award_predict_fn,
                model_info={"type": "external_injected", "name": "TransformerAdapter"}
            )


        # ì•„ë˜ëŠ” ê¸°ì¡´ì˜ 1DCNN ë¡œë”© ë¡œì§ (award_predict_fnì´ ì—†ì„ ë•Œë§Œ ì‹¤í–‰ë¨)
        if not award_model_path:
            return HeuristicAwardPricePredictor()

        try:
            module = _load_module_from_py(award_model_path)
            # ... (ê¸°ì¡´ 1DCNN ë¡œì§ë“¤) ...
            if hasattr(module, "CNN1DRegressor"):
                print("â„¹ï¸ BidRAGPipeline: ë‚´ë¶€ 1DCNN ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
                # (ìƒëµëœ 1DCNN ë¡œë“œ ì½”ë“œ ì‹¤í–‰ë¨)
                return CNN1DAwardPricePredictor(...)

            # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return HeuristicAwardPricePredictor()

    def _node_predict(self, state: GraphState) -> GraphState:
        reqs = state.get("requirements", {})
        # RAGê°€ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ìˆ˜í–‰
        retrieved_context = ""

        # â˜… ì—¬ê¸°ì„œ ì£¼ì…ëœ Transformer ì–´ëŒ‘í„°ì˜ predict()ê°€ ì‹¤í–‰ë¨
        try:
            pred_result = self.award_predictor.predict(reqs, retrieved_context)
            print("=" * 60)
            print(" [DEBUG] _node_predict - ì˜ˆì¸¡ ì™„ë£Œ:")
            print(json.dumps(pred_result, indent=2, ensure_ascii=False))
            print("=" * 60)
        except Exception as e:
            pred_result = {"error": str(e), "confidence": "low"}

        state["prediction_result"] = pred_result

        # LLMì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€ ì¶”ê°€
        pred_json = json.dumps(pred_result, ensure_ascii=False)
        sys_msg = SystemMessage(content=f"[ë‚™ì°°ê°€ ì˜ˆì¸¡ ê²°ê³¼]\n{pred_json}")

        return {"messages": [sys_msg], "prediction_result": pred_result}
    # def _build_tools(self) -> List[Any]:
    #     index = self.index
    #     top_k = self.top_k

    #     @tool
    #     def rag_retrieve(query: str) -> str:
    #         """ìœ ì‚¬ ê³µê³ /ë‚™ì°°ì‚¬ë¡€ ê²€ìƒ‰(RAG)."""
    #         chunks = index.retrieve(query=query, k=top_k)
    #         if not chunks:
    #             return "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"
    #         chunks = [c[:1200] for c in chunks]
    #         return "\n\n---\n\n".join(chunks)

    #     @tool
    #     def predict_award_price(requirements_json: str, retrieved_context: str) -> str:
    #         """ë‚™ì°°ê°€ ì˜ˆì¸¡ Tool (ToolNode ë¸”ë¡)."""
    #         try:
    #             reqs = json.loads(requirements_json)
    #             if not isinstance(reqs, dict):
    #                 reqs = {}
    #         except Exception:
    #             reqs = {}

    #         try:
    #             result = self.award_predictor.predict(reqs, retrieved_context or "")
    #         except Exception as e:
    #             result = {
    #                 "currency": "KRW",
    #                 "predicted_min": None,
    #                 "predicted_max": None,
    #                 "point_estimate": None,
    #                 "confidence": "low",
    #                 "rationale": [
    #                     "ë‚™ì°°ê°€ ì˜ˆì¸¡ ì¤‘ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ëª¨ë¸/í”¼ì²˜ íŒŒì´í”„ë¼ì¸ì„ ì ê²€í•˜ì„¸ìš”.",
    #                     f"ì˜ˆì™¸: {type(e).__name__}: {str(e)}",
    #                 ],
    #                 "model": {"type": "runtime_error"},
    #             }

    #         if not isinstance(result, dict):
    #             result = {
    #                 "currency": "KRW",
    #                 "predicted_min": None,
    #                 "predicted_max": None,
    #                 "point_estimate": None,
    #                 "confidence": "low",
    #                 "rationale": ["ë‚™ì°°ê°€ ì˜ˆì¸¡ ëª¨ë¸ ì¶œë ¥ì´ dictê°€ ì•„ë‹ˆì–´ì„œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."],
    #                 "model": {"type": "invalid_output"},
    #             }

    #         return json.dumps(result, ensure_ascii=False)

    #     @tool
    #     def competitor_analysis(requirements_json: str, retrieved_context: str) -> str:
    #         """ê²½ìŸë‚™ì°°/ê²½ìŸì‚¬ ì‹œê·¸ë„(ê²½ëŸ‰ heuristic)."""
    #         try:
    #             reqs = json.loads(requirements_json)
    #             if not isinstance(reqs, dict):
    #                 reqs = {}
    #         except Exception:
    #             reqs = {}

    #         text = retrieved_context or ""
    #         candidates: Dict[str, int] = {}
    #         for m in re.findall(r"([ê°€-í£A-Za-z0-9&()]{2,40})(?:\s*\(ì£¼\)|\s*ãˆœ)", text):
    #             name = _clean_whitespace(m)
    #             if 2 <= len(name) <= 40:
    #                 candidates[name] = candidates.get(name, 0) + 1
    #         sorted_names = sorted(candidates.items(), key=lambda x: x[1], reverse=True)
    #         top_names = [n for n, _ in sorted_names[:8]]

    #         barriers = []
    #         if len(reqs.get("qualification_requirements", [])) >= 5:
    #             barriers.append("ì°¸ê°€ìê²© ìš”ê±´ì´ ë‹¤ìˆ˜ë¡œ ë³´ì´ë©°, ìê²© ì¶©ì¡±ì´ 1ì°¨ í•„í„°ë¡œ ì‘ë™í•  ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.")
    #         if len(reqs.get("performance_requirements", [])) >= 5:
    #             barriers.append("ìœ ì‚¬ì‹¤ì /ì‹¤ì ìš”ê±´ì´ ê°•í•´ ì‹ ê·œ/ì¤‘ì†Œ ì‚¬ì—…ì ì§„ì…ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    #         if reqs.get("bid_method"):
    #             barriers.append(f"í‰ê°€/ë‚™ì°° ë°©ì‹({reqs.get('bid_method')})ì— ë”°ë¼ ê¸°ìˆ /ê°€ê²© ì „ëµì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤.")

    #         result = {
    #             "likely_competitors": top_names or [],
    #             "market_signals": barriers,
    #             "recommended_positioning": [
    #                 "ìš”êµ¬ì‚¬í•­ ë§¤í•‘í‘œ(ìš”êµ¬ì‚¬í•­-ê·¼ê±°-ì¦ë¹™)ë¥¼ ì œì•ˆì„œ ìµœìƒë‹¨ì— ë°°ì¹˜í•´ ëˆ„ë½ ë¦¬ìŠ¤í¬ë¥¼ ì œê±°í•©ë‹ˆë‹¤.",
    #                 "ìœ ì‚¬ì‹¤ì /í•µì‹¬ì¸ë ¥/í’ˆì§ˆ(ë³´ì•ˆ/ì•ˆì „) ì²´ê³„ë¥¼ ëª…í™•íˆ ì œì‹œí•´ ê¸°ìˆ í‰ê°€ ë¦¬ìŠ¤í¬ë¥¼ ë‚®ì¶¥ë‹ˆë‹¤.",
    #                 "ë‚™ì°°ê°€ ì „ëµì€ 'ì˜ˆì¸¡ê°’ + ìœ ì‚¬ ë‚™ì°°ì‚¬ë¡€ ë¶„í¬ + ë‚´ë¶€ ì›ê°€/ë§ˆì§„'ìœ¼ë¡œ ìµœì¢… ê²°ì •í•©ë‹ˆë‹¤.",
    #             ],
    #             "confidence": "low" if retrieved_context in ("", "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)") else "medium",
    #         }
    #         return json.dumps(result, ensure_ascii=False)

    #     return [rag_retrieve, predict_award_price, competitor_analysis]

    def _build_graph(self):
        workflow = StateGraph(GraphState)

        # ë…¸ë“œ ë“±ë¡
        workflow.add_node("extract", self._node_extract)
        workflow.add_node("predict", self._node_predict)
        workflow.add_node("report", self._node_report)

        # ì—£ì§€ ì—°ê²° (ì¡°ê±´ë¬¸ ì—†ì´ ì§ë ¬ ì—°ê²°)
        workflow.add_edge(START, "extract")
        workflow.add_edge("extract", "predict")
        workflow.add_edge("predict", "report")
        workflow.add_edge("report", END)

        return workflow.compile(checkpointer=MemorySaver())

    # ------------------------------
    # Graph nodes
    # ------------------------------

    def _node_extract(self, state: GraphState) -> GraphState:
        messages = state.get("messages", [])
        if not messages:
            raise ValueError("State must start with messages containing HumanMessage.")

        bid_text = ""
        for m in messages:
            if isinstance(m, HumanMessage):
                bid_text = m.content
                break

        sys = SystemMessage(
            content=(
                "ë„ˆëŠ” ì¡°ë‹¬/ì…ì°°(ì œì•ˆ/íˆ¬ì°°) ë¶„ì„ê°€ë‹¤. "
                "ì‚¬ìš©ìê°€ ì œê³µí•œ ê³µê³ ë¬¸ í…ìŠ¤íŠ¸ì—ì„œ ìš”êµ¬ì‚¬í•­ì„ êµ¬ì¡°í™”í•´ ì¶”ì¶œí•˜ë¼. "
                "ìˆ«ìëŠ” ê°€ëŠ¥í•˜ë©´ ì› ë‹¨ìœ„ ìˆ«ì(float/int)ë¡œ ì •ê·œí™”í•˜ê³ , "
                "í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ nullë¡œ ë‘”ë‹¤. "
                "íŠ¹íˆ ë‚™ì°°ê°€ ëª¨ë¸ ì…ë ¥ì„ ìœ„í•´ ì˜ˆê°€ë²”ìœ„(expected_price_range), ë‚™ì°°í•˜í•œìœ¨(award_lower_rate)ë„ ì¶”ì¶œì„ ì‹œë„í•˜ë¼.\n\n"
                "ì¤‘ìš”: ë‹¤ìŒ 3ê°€ì§€ë¥¼ ì¶”ì¶œí•˜ë¼ (ê³µê³ ë¬¸ì— ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ìš”ê±´ ì œì‹œ):\n\n"
                "1) qualification_requirements (ì°¸ê°€ìê²©):\n"
                "   **ìš°ì„ ìˆœìœ„ 1: ê³µê³ ë¬¸ì—ì„œ ì§ì ‘ ì°¾ê¸°**\n"
                "   - ê³µê³ ë¬¸ì—ì„œ 'ë©´í—ˆ', 'ë“±ë¡', 'ìê²©', 'ì—…ì¢…', 'í—ˆê°€' ë“±ì´ í¬í•¨ëœ ë¬¸ì¥ ì°¾ê¸°\n"
                "   - ì˜ˆ: 'ê±´ì„¤ì—… ë©´í—ˆ ë³´ìœ ì', 'ì¡°ê²½ê³µì‚¬ì—… ë“±ë¡ì—…ì²´'\n"
                "   **ìš°ì„ ìˆœìœ„ 2: ê³µê³ ë¬¸ì— ì—†ìœ¼ë©´ ì¼ë°˜ ìš”ê±´ ì œì‹œ**\n"
                "   - title í•„ë“œë¥¼ ë³´ê³  ê³µì‚¬/ìš©ì—­ ìœ í˜• íŒŒì•…\n"
                "   - ê³µì‚¬ (ì˜ˆ: 'â—‹â—‹ê³µì‚¬', 'ì‹œì„¤ê³µì‚¬', 'ê±´ì¶•'): ['ê±´ì„¤ì—… ë©´í—ˆ ë³´ìœ ', 'í•´ë‹¹ ì—…ì¢… ë“±ë¡ì—…ì²´']\n"
                "   - ìš©ì—­ (ì˜ˆ: 'â—‹â—‹ìš©ì—­', 'ì»¨ì„¤íŒ…'): ['ì‚¬ì—…ìë“±ë¡ì¦ ë³´ìœ ', 'ê´€ë ¨ ì—…ì¢… ë“±ë¡']\n"
                "   - ë¬¼í’ˆ: ['ì œì¡°ì—…ì²´ ë˜ëŠ” íŒë§¤ì—…ì²´']\n\n"
                "2) performance_requirements (ì‹¤ì ìš”ê±´):\n"
                "   **ìš°ì„ ìˆœìœ„ 1: ê³µê³ ë¬¸ì—ì„œ ì§ì ‘ ì°¾ê¸°**\n"
                "   - 'ì‹¤ì ', 'ìœ ì‚¬', 'ë™ì¼', 'ìˆ˜í–‰ê²½í—˜' ë“±ì´ í¬í•¨ëœ ë¬¸ì¥\n"
                "   **ìš°ì„ ìˆœìœ„ 2: ê³µê³ ë¬¸ì— ì—†ìœ¼ë©´ ì¼ë°˜ ìš”ê±´ ì œì‹œ**\n"
                "   - ê³µì‚¬: ['ìœ ì‚¬ ê³µì‚¬ ì‹¤ì  ë³´ìœ ']\n"
                "   - ìš©ì—­: ['ìœ ì‚¬ ìš©ì—­ ìˆ˜í–‰ ì‹¤ì ']\n"
                "   - ë¬¼í’ˆ: ['ë‚©í’ˆ ì‹¤ì ']\n\n"
                "3) document_requirements (ì œì¶œì„œë¥˜):\n"
                "   - ê¸°ë³¸ ì„œë¥˜ëŠ” í•­ìƒ í¬í•¨: ['ì…ì°°ì°¸ê°€ì‹ ì²­ì„œ', 'ì‚¬ì—…ìë“±ë¡ì¦']\n"
                "   - ê³µê³ ë¬¸ì— ì¶”ê°€ ì„œë¥˜ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ í•¨ê»˜ í¬í•¨\n"
                "   - ê³µì‚¬ì¸ ê²½ìš°: ê±´ì„¤ì—…ë“±ë¡ì¦, ì‹¤ì ì¦ëª…ì„œë„ ì¼ë°˜ì ìœ¼ë¡œ í¬í•¨\n\n"
                "í•µì‹¬:\n"
                "- ê³µê³ ë¬¸ì— ëª…ì‹œëœ ë‚´ìš© ìš°ì„ \n"
                "- ì—†ìœ¼ë©´ ê³µì‚¬/ìš©ì—­ ìœ í˜• ë³´ê³  ì¼ë°˜ì ì¸ ìš”ê±´ ì œì‹œ\n"
                "- ì ˆëŒ€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë‘ì§€ ë§ˆë¼"
            )
        )

        try:
            extractor = self.llm.with_structured_output(BidRequirements)
            reqs_obj: BidRequirements = extractor.invoke([sys, HumanMessage(content=bid_text)])
            reqs_dict = reqs_obj.model_dump()
        except Exception:
            fallback = self.llm.invoke(
                [
                    sys,
                    HumanMessage(
                        content=(
                            "ë‹¤ìŒ ê³µê³ ë¬¸ì„ ì½ê³  ì•„ë˜ í‚¤ë¥¼ ê°–ëŠ” JSONë§Œ ì¶œë ¥í•´ë¼:\n"
                            "title, agency, category, region, deadline, budget, estimate_price, "
                            "expected_price_range, award_lower_rate, bid_method, "
                            "qualification_requirements, performance_requirements, document_requirements, risk_flags\n\n"
                            + bid_text
                        )
                    ),
                ]
            )
            text = fallback.content if isinstance(fallback, AIMessage) else str(fallback)
            match = re.search(r"\{.*\}", text, flags=re.DOTALL)
            parsed = {}
            if match:
                try:
                    parsed = json.loads(match.group(0))
                except Exception:
                    parsed = {}
            reqs_dict = parsed

        for k in ["qualification_requirements", "performance_requirements", "document_requirements", "risk_flags"]:
            val = reqs_dict.get(k, [])
            if isinstance(val, list):
                reqs_dict[k] = [_clean_whitespace(x) for x in val if str(x).strip()]

        # ğŸ”§ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²´í¬ ë° ê¸°ë³¸ê°’ ì¶”ê°€
        title = reqs_dict.get('title', '') or ''
        category = reqs_dict.get('category', '') or ''
        title_lower = title.lower()
        category_lower = category.lower()

        # 1) ì°¸ê°€ìê²©ì´ ë¹„ì–´ìˆìœ¼ë©´ ê³µì‚¬/ìš©ì—­ ìœ í˜•ì— ë”°ë¼ ê¸°ë³¸ê°’ ì¶”ê°€
        if not reqs_dict.get('qualification_requirements'):
            if 'ê³µì‚¬' in title or 'ê±´ì„¤' in title or 'ì‹œì„¤' in title or 'ì¡°ì„±' in title:
                reqs_dict['qualification_requirements'] = ['í•´ë‹¹ ì—…ì¢… ê±´ì„¤ì—… ë©´í—ˆ ë³´ìœ ì']
            elif 'ìš©ì—­' in title or 'ì»¨ì„¤íŒ…' in title:
                reqs_dict['qualification_requirements'] = ['í•´ë‹¹ ë¶„ì•¼ ì‚¬ì—…ìë“±ë¡ ë˜ëŠ” ë©´í—ˆ ë³´ìœ ì']
            elif 'ë¬¼í’ˆ' in title or 'êµ¬ë§¤' in title:
                reqs_dict['qualification_requirements'] = ['í•´ë‹¹ ë¬¼í’ˆ ì œì¡° ë˜ëŠ” íŒë§¤ì—… ë“±ë¡ì']
            else:
                reqs_dict['qualification_requirements'] = ['ì‚¬ì—…ìë“±ë¡ ë³´ìœ ì']

        # 2) ì‹¤ì ìš”ê±´ì´ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
        if not reqs_dict.get('performance_requirements'):
            if 'ê³µì‚¬' in title or 'ê±´ì„¤' in title or 'ì‹œì„¤' in title or 'ì¡°ì„±' in title:
                reqs_dict['performance_requirements'] = ['ìœ ì‚¬ ê³µì‚¬ ìˆ˜í–‰ì‹¤ì  (ê³µê³ ë¬¸ ì²¨ë¶€íŒŒì¼ í™•ì¸ í•„ìš”)']
            elif 'ìš©ì—­' in title or 'ì»¨ì„¤íŒ…' in title:
                reqs_dict['performance_requirements'] = ['ìœ ì‚¬ ìš©ì—­ ìˆ˜í–‰ì‹¤ì  (ê³µê³ ë¬¸ ì²¨ë¶€íŒŒì¼ í™•ì¸ í•„ìš”)']
            elif 'ë¬¼í’ˆ' in title or 'êµ¬ë§¤' in title:
                reqs_dict['performance_requirements'] = ['ë™ì¼ ë˜ëŠ” ìœ ì‚¬ ë¬¼í’ˆ ë‚©í’ˆì‹¤ì  (ê³µê³ ë¬¸ ì²¨ë¶€íŒŒì¼ í™•ì¸ í•„ìš”)']
            else:
                reqs_dict['performance_requirements'] = ['ìœ ì‚¬ í”„ë¡œì íŠ¸ ìˆ˜í–‰ì‹¤ì  (ê³µê³ ë¬¸ ì²¨ë¶€íŒŒì¼ í™•ì¸ í•„ìš”)']

        # 3) ì œì¶œì„œë¥˜ëŠ” ê¸°ë³¸ ì„œë¥˜ í•­ìƒ í¬í•¨
        if not reqs_dict.get('document_requirements'):
            reqs_dict['document_requirements'] = ['ì…ì°°ì°¸ê°€ì‹ ì²­ì„œ', 'ì‚¬ì—…ìë“±ë¡ì¦']
            if 'ê³µì‚¬' in title or 'ê±´ì„¤' in title:
                reqs_dict['document_requirements'].extend(['ê±´ì„¤ì—…ë“±ë¡ì¦', 'ì‹¤ì ì¦ëª…ì„œ'])
        else:
            # ê¸°ë³¸ ì„œë¥˜ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            docs = reqs_dict['document_requirements']
            if 'ì…ì°°ì°¸ê°€ì‹ ì²­ì„œ' not in docs:
                docs.insert(0, 'ì…ì°°ì°¸ê°€ì‹ ì²­ì„œ')
            if 'ì‚¬ì—…ìë“±ë¡ì¦' not in docs:
                docs.insert(1, 'ì‚¬ì—…ìë“±ë¡ì¦')

        # ğŸ” ë””ë²„ê¹…: ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­ ì¶œë ¥
        print("=" * 60)
        print(" [DEBUG] ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­:")
        print(f"  - ì°¸ê°€ìê²©: {reqs_dict.get('qualification_requirements', [])}")
        print(f"  - ì‹¤ì ìš”ê±´: {reqs_dict.get('performance_requirements', [])}")
        print(f"  - ì œì¶œì„œë¥˜: {reqs_dict.get('document_requirements', [])}")
        print("=" * 60)

        state["requirements"] = reqs_dict
        return state

    def _node_agent(self, state: GraphState) -> GraphState:
        reqs = state.get("requirements", {})
        reqs_json = json.dumps(reqs, ensure_ascii=False)

        sys = SystemMessage(
            content=(
                "ë„ˆëŠ” ì œì•ˆ/íˆ¬ì°° agentë‹¤. ë‹¤ìŒ ìˆœì„œë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•´ ê·¼ê±°ë¥¼ ìˆ˜ì§‘í•˜ë¼.\n"
                "1) rag_retrieve(query): ê³µê³  ìš”ì•½ + í•µì‹¬ í‚¤ì›Œë“œë¡œ ìœ ì‚¬ ê³µê³ /ë‚™ì°°ì‚¬ë¡€ ê²€ìƒ‰\n"
                "2) predict_award_price(requirements_json, retrieved_context): ë‚™ì°°ê°€ ì˜ˆì¸¡(ì‚¬ìš©ì ëª¨ë¸)\n"
                "3) competitor_analysis(requirements_json, retrieved_context): ê²½ìŸ/ì‹œì¥ ì‹œê·¸ë„ ì‚°ì¶œ\n\n"
                "ë„êµ¬ í˜¸ì¶œì´ ëª¨ë‘ ëë‚˜ë©´, ë” ì´ìƒ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ê³  ì¢…ë£Œí•˜ë¼."
            )
        )

        context_msg = SystemMessage(content="[ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­ JSON]\n" + reqs_json)
        messages = state.get("messages", [])
        bound = self.llm.bind_tools(self.tools)
        ai = bound.invoke([sys, context_msg] + messages)
        state["messages"] = messages + [ai]
        return state

    def _should_continue(self, state: GraphState) -> str:
        messages = state.get("messages", [])
        if not messages:
            return "report"
        last = messages[-1]
        if isinstance(last, AIMessage) and getattr(last, "tool_calls", None):
            return "tools"
        return "report"

    def _node_report(self, state: GraphState) -> GraphState:
        reqs = state.get("requirements", {})
        pred = state.get("prediction_result", {})
        print("=" * 60)
        print(" [DEBUG] _node_report - prediction_result:")
        print(json.dumps(pred, indent=2, ensure_ascii=False))
        print("=" * 60)

        reqs_json = json.dumps(reqs, ensure_ascii=False)
        pred_json = json.dumps(pred, ensure_ascii=False)
        messages = state.get("messages", [])

        sys = SystemMessage(
            content=(
                "ë„ˆëŠ” ì¡°ë‹¬/ì…ì°°(ì œì•ˆ/íˆ¬ì°°) ì»¨ì„¤í„´íŠ¸ë‹¤. "
                "ì•„ë˜ì˜ (1) ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­ JSON, (2) ë„êµ¬ ì¶œë ¥ë“¤ì„ ê·¼ê±°ë¡œ "
                "ì‹¤ë¬´ìê°€ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” 'ì œì•ˆ/íˆ¬ì°° ë¶„ì„ ë¦¬í¬íŠ¸'ë¥¼ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•˜ë¼.\n\n"
                "í•„ìˆ˜ ì„¹ì…˜(ìˆœì„œ ìœ ì§€):\n"
                "# 1. ê³µê³  ìš”ì•½\n"
                "# 2. ì°¸ê°€ìê²©/ì‹¤ì /ì œì¶œì„œë¥˜ ì²´í¬ë¦¬ìŠ¤íŠ¸\n"
                "   ì´ ì„¹ì…˜ì€ 3ê°œì˜ ì†Œì œëª©ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ë¼:\n\n"
                "   ## ê°€. ì°¸ê°€ìê²© ìš”ê±´\n"
                "   qualification_requirements ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ í‘œì‹œ:\n"
                "   - í˜•ì‹: 'â€¢ í•­ëª©ëª…' (ë¶ˆë¦¿ í¬ì¸íŠ¸ë§Œ ì‚¬ìš©, ì²´í¬ë°•ìŠ¤ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€)\n"
                "   - ì˜ˆì‹œ:\n"
                "     â€¢ ê±´ì„¤ì—… ë©´í—ˆ ë³´ìœ ì\n"
                "     â€¢ ì¡°ê²½ê³µì‚¬ì—… ë“±ë¡ì—…ì²´\n"
                "   - ë¦¬ìŠ¤íŠ¸ì— í•­ëª©ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ í‘œì‹œ\n"
                "   - ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì–´ë„ ì ˆëŒ€ 'ê³µê³ ë¬¸ì— ëª…ì‹œëœ ìê²©ìš”ê±´ ì—†ìŒ'ì´ë¼ê³  ì“°ì§€ ë§ˆë¼\n\n"
                "   ## ë‚˜. ì‹¤ì  ìš”ê±´\n"
                "   performance_requirements ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ í‘œì‹œ:\n"
                "   - í˜•ì‹: 'â€¢ í•­ëª©ëª…' (ë¶ˆë¦¿ í¬ì¸íŠ¸ë§Œ ì‚¬ìš©)\n"
                "   - ì˜ˆì‹œ: 'â€¢ ìµœê·¼ 3ë…„ ì´ë‚´ ìœ ì‚¬ê³µì‚¬ ì‹¤ì  1ê±´ ì´ìƒ'\n"
                "   - ë¦¬ìŠ¤íŠ¸ì— í•­ëª©ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ í‘œì‹œ\n\n"
                "   ## ë‹¤. ì œì¶œì„œë¥˜\n"
                "   document_requirements ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ í‘œì‹œ:\n"
                "   - í˜•ì‹: 'â€¢ í•­ëª©ëª…' (ë¶ˆë¦¿ í¬ì¸íŠ¸ë§Œ ì‚¬ìš©)\n"
                "   - ì˜ˆì‹œ:\n"
                "     â€¢ ì…ì°°ì°¸ê°€ì‹ ì²­ì„œ\n"
                "     â€¢ ì‚¬ì—…ìë“±ë¡ì¦\n"
                "     â€¢ ê±´ì„¤ì—…ë“±ë¡ì¦\n"
                "   - ë¦¬ìŠ¤íŠ¸ì— í•­ëª©ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ í‘œì‹œ\n\n"
                "   âš ï¸ ì¤‘ìš”: ì ˆëŒ€ë¡œ '- [ ]' ì²´í¬ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆë¼. ì˜¤ì§ 'â€¢' ë¶ˆë¦¿ë§Œ ì‚¬ìš©í•˜ë¼.\n\n"
                                # =========================================================
                # [ëª¨ë¸v2ëŒ€ì‘] ì„¹ì…˜ 3 í”„ë¡¬í”„íŠ¸ë¥¼ "top_ranges ìˆìœ¼ë©´ TFT í˜•ì‹ / ì—†ìœ¼ë©´ v2 í˜•ì‹"ìœ¼ë¡œ ë³€ê²½
                # =========================================================
                "# 3. ë‚™ì°°ê°€ ì˜ˆì¸¡(ë²”ìœ„/í¬ì¸íŠ¸/ê·¼ê±°/)\n"
                "   - ì˜ˆì¸¡ ê²°ê³¼(prediction_result)ì— ë”°ë¼ ë‹¤ìŒ 2ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ì‘ì„±í•˜ë¼.\n\n"
                "   [Aì•ˆ: top_rangesê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°]\n"
                "   - (ê¸°ì¡´ ë°©ì‹ ìœ ì§€) ë°˜ë“œì‹œ '### ì‚¬ì •ìœ¨ êµ¬ê°„ì— ë”°ë¥¸ ìƒìœ„ 3ê°œì˜ í™•ë¥ ' ì†Œì œëª©ì„ í¬í•¨í•˜ë¼.\n"
                "   - top_rangesì˜ ê° í•­ëª©ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í‘œì‹œ:\n"
                "     * range_display (êµ¬ê°„)\n"
                "     * rate (ì‚¬ì •ìœ¨)\n"
                "     * probability (í™•ë¥ )\n"
                "   - í˜•ì‹: 'â€¢ Nìˆœìœ„: êµ¬ê°„ {range_display}, ì‚¬ì •ìœ¨ {rate:.2f}%, í™•ë¥  {probability:.2f}%'\n\n"
                "   [Bì•ˆ: top_rangesê°€ ì—†ëŠ” ê²½ìš° (V2 ëª¨ë¸)]\n"
                "   - ì•„ë˜ 3ì¤„ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ë¼(ìˆœì„œ ìœ ì§€):\n"
                "     1) ì˜ˆì¸¡ íˆ¬ì°°ìœ¨(%): predicted_percent\n"
                "     2) ì˜ˆì¸¡ ë‚™ì°°ê°€(ì›): point_estimate (ê¸°ì´ˆê¸ˆì•¡ Ã— íˆ¬ì°°ìœ¨ Ã— ë‚™ì°°í•˜í•œìœ¨)\n"
                "     3) ê·¼ê±°: 'v2 ëª¨ë¸ ê²°ê³¼ + (y_pred_transformed / 100) + 100 ì—­ì‚° ì ìš©'\n"
                "   - í˜•ì‹ì€ ê¹”ë”í•œ ë¶ˆë¦¿ ë˜ëŠ” í•œ ì¤„ ìš”ì•½ í˜•íƒœë¡œ ì‘ì„±í•˜ë¼.\n"

                "# 4. ê¶Œê³  ì•¡ì…˜(ë‹¤ìŒ 72ì‹œê°„ To-Do)\n\n"
                "ì œì•½: ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ 'ê°€ì •'ìœ¼ë¡œ ëª…ì‹œí•˜ê³  ì¶”ê°€ ìˆ˜ì§‘ í•­ëª©ì„ ì œì‹œí•˜ë¼."
            )
        )
        ctx = SystemMessage(content=(
        f"[ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­]\n{reqs_json}\n\n"
        f"[ë‚™ì°°ê°€ ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼]\n{pred_json}"
        ))
        final = self.llm.invoke([sys, ctx] + messages)
        report = final.content if isinstance(final, AIMessage) else str(final)

        import re
        report = re.sub(
            r'(êµ¬ê°„\s*)(\d+\.\d{2})\d*%\s*~\s*(\d+\.\d{2})\d*%',
            r'\1\2% ~ \3%',
            report
        )




        state["report_markdown"] = report
        return state

    # ------------------------------
    # Public API
    # ------------------------------

    def analyze(self, bid_notice_text: str, thread_id: str = "default") -> Dict[str, Any]:
        initial: GraphState = {"messages": [HumanMessage(content=bid_notice_text)]}
        final_state: GraphState = self.graph.invoke(initial, config={"configurable": {"thread_id": thread_id}})
        return {
            "requirements": final_state.get("requirements", {}),
            "prediction_result": final_state.get("prediction_result", {}),
            "report_markdown": final_state.get("report_markdown", ""),
            "messages": final_state.get("messages", []),
        }


# ------------------------------
# CLI entry
# ------------------------------

if __name__ == "__main__":
    import argparse
    import sys
    from datetime import datetime
    import uuid

    try:
        from md2pdf.md2pdf import md2pdf
    except ImportError:
        print("ERROR: md2pdf not installed. Run: pip install md2pdf")
        sys.exit(1)

    parser = argparse.ArgumentParser(description="Bid Assistance RAG Pipeline")
    parser.add_argument("--doc_dir", default="./rag_corpus")
    parser.add_argument("--index_dir", default="./rag_index")
    parser.add_argument("--input", default=None, help="Bid notice file (.txt or .pdf)")

    parser.add_argument(
        "--award_model",
        default=None,
        help=(
            "ë‚™ì°°ê°€ ì˜ˆì¸¡ ëª¨ë¸ python íŒŒì¼(.py). "
            "Wrapper mode: predict_award_price(requirements, retrieved_context) ë˜ëŠ” predict(requirements, retrieved_context). "
            "Auto mode: model_1dcnn.pyë¥¼ ì§€ì •í•˜ê³  --award_weights/--award_scalerë¥¼ í•¨ê»˜ ì§€ì •."
        ),
    )
    parser.add_argument("--award_weights", default=None, help="CNN1D ê°€ì¤‘ì¹˜ íŒŒì¼(.pt). ì˜ˆ: ./results/best_model.pt")
    parser.add_argument("--award_scaler", default=None, help="CNN1D scaler íŒŒì¼(.json/.npz). ì˜ˆ: ./results/scalers.json")
    parser.add_argument("--award_device", default=None, help="torch device. ì˜ˆ: cpu ë˜ëŠ” cuda")
    parser.add_argument("--award_hidden", type=int, default=64, help="CNN1D hidden size (í•™ìŠµê³¼ ë™ì¼í•´ì•¼ í•¨)")
    parser.add_argument("--award_dropout", type=float, default=0.1, help="CNN1D dropout (í•™ìŠµê³¼ ë™ì¼í•´ì•¼ í•¨)")

    args = parser.parse_args()

    text = ""
    if args.input and os.path.exists(args.input):
        text = read_input_text(args.input)
    else:
        print("Paste bid notice text, then end input with EOF (Ctrl-D / Ctrl-Z).")
        try:
            text = sys.stdin.read()
        except Exception:
            text = ""

    pipe = BidRAGPipeline(
        doc_dir=args.doc_dir,
        index_dir=args.index_dir,
        award_model_path=args.award_model,
        award_weights_path=args.award_weights,
        award_scaler_path=args.award_scaler,
        award_device=args.award_device,
        award_hidden=args.award_hidden,
        award_dropout=args.award_dropout,
    )
    out = pipe.analyze(text)
    markdown_content = out["report_markdown"]
    print(out["report_markdown"])

    # 3. ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)

    # 4. PDF ì €ì¥ ê²½ë¡œ ê²°ì •
    if args.output_pdf:
        pdf_path = args.output_pdf
    else:
        # ìë™ìœ¼ë¡œ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_id = str(uuid.uuid4())[:8]
        pdf_filename = f"analysis_report_{file_id}_{timestamp}.pdf"
        pdf_path = os.path.join(args.output_dir, pdf_filename)

    # 5. ë§ˆí¬ë‹¤ìš´ â†’ PDF ë³€í™˜
    try:
        md2pdf(
            md_file_contents=markdown_content,
            output_file=pdf_path
        )
        print(f"âœ“ PDF ì €ì¥ ì™„ë£Œ: {pdf_path}")
    except Exception as e:
        print(f"âœ— PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨í•´ë„ ë§ˆí¬ë‹¤ìš´ì€ ì¶œë ¥
        print("\n--- Markdown Content (PDF ë³€í™˜ ì‹¤íŒ¨) ---\n")
        print(markdown_content)
        sys.exit(1)

    # 6. ê²°ê³¼ ì¶œë ¥ (ë§ˆí¬ë‹¤ìš´ ì›ë³¸ë„ ì¶œë ¥í•˜ë ¤ë©´)
    print("\n--- Generated Report (Markdown) ---\n")
    print(markdown_content)

    # 7. ë°±ì—”ë“œë¡œ ì „ì†¡í•  ì •ë³´ (JSON)
    result_json = {
        "pdf_path": pdf_path,
        "summary_link": pdf_path,  # ë˜ëŠ” ìƒëŒ€ê²½ë¡œ: f"/reports/{os.path.basename(pdf_path)}"
        "requirements": out["requirements"],
    }
    print("\n--- Payload to Backend ---\n")
    print(json.dumps(result_json, indent=2, ensure_ascii=False))