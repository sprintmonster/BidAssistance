import os
import pandas as pd
from PIL import Image
import pytesseract

from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import ImageCaptionLoader, UnstructuredExcelLoader, TextLoader
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from typing import List, Dict
import re

# from usage_tool import usage_tool : í…ŒìŠ¤íŠ¸ í•˜ë ¤ë©´ í™œì„±í™”

# test_usage_tool.py : í˜„ì¬ ìœ„ì¹˜ì— faiss_db í´ë”ë¥¼ ìƒì„± + usage_tool.py ë™ì‘ í…ŒìŠ¤íŠ¸
# C:\BGPJ\BidAssitance\AI_Models\usage_data\images
# =========================
# ê²½ë¡œ ì„¤ì •
# =========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
IMAGE_DIR = os.path.join(BASE_DIR, "usage_data", "images")
API_EXCEL_DIR = os.path.join(BASE_DIR, "usage_data", "apiì •ì˜ì„œ.xlsx")
TEXT_DIR=os.path.join(BASE_DIR,"usage_data","í™ˆí˜ì´ì§€ ì‚¬ìš© ì„¤ëª…ì„œ.txt")

from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent
IMAGE_FAISS_DIR = BASE_DIR / "faiss_db" / "image_faiss"
API_FAISS_DIR= BASE_DIR / "faiss_db" / "api_faiss"
TEXT_FAISS_DIR= BASE_DIR / "faiss_db" / "txt_faiss"

# =========================
# FAISS ìƒì„± ì„ë² ë”© ëª¨ë¸ ì„¤ì •
# =========================
from dotenv import load_dotenv
load_dotenv()


embeddings = OpenAIEmbeddings(model = "text-embedding-3-small") # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”

# =========================
# 1ï¸âƒ£ ì´ë¯¸ì§€ â†’ image FAISS ìƒì„± (ImageCaptionLoader, ë‹¤ë¥¸ ì½”ë“œì—ì„œ í•„ìš”ì‹œ ë¶™ì—¬ë†“ê¸°) 
# =========================
def build_image_faiss():
    print("ğŸ”¹ image FAISS ìƒì„± ì¤‘ (ImageCaptionLoader)...")
    if not os.path.exists(IMAGE_DIR):
        raise FileNotFoundError(f"ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {IMAGE_DIR}")

    # 1ï¸âƒ£ ì´ë¯¸ì§€ íŒŒì¼ ì „ì²´ ìˆ˜ì§‘
    image_paths = [
        os.path.join(IMAGE_DIR, f)
        for f in os.listdir(IMAGE_DIR)
        if f.lower().endswith((".png", ".jpg", ".jpeg"))
    ]

    if not image_paths:
        raise RuntimeError("ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # 2ï¸âƒ£ ImageCaptionLoader ì‚¬ìš©
    loader = ImageCaptionLoader(image_paths)
    documents = loader.load()
    # 3ï¸âƒ£ metadata ë³´ê°•
    for doc in documents:
        doc.metadata["source"] = "image"
        doc.metadata["type"] = "screenshot"
    # 4ï¸âƒ£ FAISS ìƒì„±
    faiss = FAISS.from_documents(documents, embeddings)
    faiss.save_local(IMAGE_FAISS_DIR)

# =========================
# 2ï¸âƒ£ ì—‘ì…€ â†’ api FAISS ìƒì„± (UnstructuredExcelLoader, ë‹¤ë¥¸ ì½”ë“œì—ì„œ í•„ìš”ì‹œ ë¶™ì—¬ë†“ê¸°)
# =========================
def build_api_faiss():
    print("ğŸ”¹ api FAISS ìƒì„± ì¤‘ (UnstructuredExcelLoader)...")
    if not os.path.exists(API_EXCEL_DIR):
        raise FileNotFoundError(f"ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {API_EXCEL_DIR}")

    #ì—‘ì…€ ë¡œë“œ
    df = pd.read_excel(API_EXCEL_DIR)

    documents = []

    # âœ… 2. row í•˜ë‚˜ë¥¼ Document í•˜ë‚˜ë¡œ ë³€í™˜
    for i, row in df.iterrows():
        rest_api = str(row["REST API"])
        input_data = str(row["ì…ë ¥ë°ì´í„°"])
        output_data = str(row["ë°˜í™˜ë°ì´í„°"])
        error_data = str(row["ì˜¤ë¥˜ë°ì´í„°"])

        content = f"""
        [API URL]
        {rest_api}

        [ì„¤ëª…]
        ì´ APIëŠ” {rest_api} ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

        [ì…ë ¥ë°ì´í„°]
        {input_data}

        [ë°˜í™˜ë°ì´í„°]
        {output_data}

        [ì˜¤ë¥˜ë°ì´í„°]
        {error_data}
        """

    doc = Document(
        page_content=content,
        metadata={
            "source": "api_excel",
            "row": i,
            "api_name": rest_api
        }
    )

    documents.append(doc)

    if not documents:
        raise RuntimeError("ì—‘ì…€ì—ì„œ ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    print(f"ì´ {len(documents)}ê°œì˜ API row ë¬¸ì„œ ìƒì„± ì™„ë£Œ")


    # 2ï¸âƒ£ ë©”íƒ€ë°ì´í„° ë³´ê°• (ê¶Œì¥)
    for idx, doc in enumerate(documents):
        doc.metadata.update({
            "source": "api_excel",
            "element_id": idx
        })
    # 3ï¸âƒ£ FAISS ìƒì„±
    faiss = FAISS.from_documents(documents, embeddings)
    faiss.save_local(API_FAISS_DIR)

def parse_manual_txt(filepath: str) -> List[Document]:
    """[í˜ì´ì§€ëª…] ë‹¨ìœ„ë¡œ txt ì„¤ëª…ì„œë¥¼ Documentë¡œ ë¶„ë¦¬"""

    with open(filepath, "r", encoding="utf-8") as f:
        raw_text = f.read()

    # [ê²Œì‹œê¸€ í˜ì´ì§€] ê°™ì€ í—¤ë” ê¸°ì¤€ split
    pattern = r"\[(.*?)\]"
    splits = re.split(pattern, raw_text)

    documents = []

    # splits êµ¬ì¡°:
    # ["", "ì „ì²´ í˜ì´ì§€ ê³µí†µ ì‚¬í•­", "ë‚´ìš©...", "ê²Œì‹œê¸€ í˜ì´ì§€", "ë‚´ìš©...", ...]

    for i in range(1, len(splits), 2):
        header = splits[i].strip()
        content = splits[i + 1].strip()

        if not content:
            continue
        
        # í˜ì´ì§€ / ì„¹ì…˜ ë¶„ë¦¬
        if " - " in header:
            page, section = header.split(" - ", 1)
        else:
            page = header
            section = "ê°œìš”"

        documents.append(
            Document(
                page_content=content,
                metadata={
                    "source": "homepage_manual",
                    "page": page.strip(),
                    "section":section.strip(),
                    "title":header
                }
            )
        )

    return documents

 # ìˆ˜ì • í•„ìš”
def build_text_faiss():
    print("ğŸ”¹ text FAISS ìƒì„± ì¤‘ (TextLoader)...")
    if not os.path.exists(TEXT_DIR):
        raise FileNotFoundError(f"í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {TEXT_DIR}")

    # 1ï¸âƒ£ í˜ì´ì§€ ë‹¨ìœ„ parsing
    documents = parse_manual_txt(TEXT_DIR)

    if not documents:
        raise RuntimeError("í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    print(f"âœ… í˜ì´ì§€ ë‹¨ìœ„ ë¬¸ì„œ ìˆ˜: {len(documents)}")

    # 2ï¸âƒ£ ë©”íƒ€ë°ì´í„° ë³´ê°• (ê¶Œì¥)
    for idx, doc in enumerate(documents):
        doc.metadata.update({
            "source": "homepage_manual",
            "element_id": idx,
            "page": doc.metadata.get("page"),
            "section": doc.metadata.get("section"),
            "type": "ui_manual"
        })
    # 3ï¸âƒ£ FAISS ìƒì„±
    faiss = FAISS.from_documents(documents, embeddings)
    faiss.save_local(TEXT_FAISS_DIR)

# =========================
# FAISS ê°’ ë¶ˆëŸ¬ì˜¤ê¸° (image / api / text ë¶„ë¦¬)
# =========================
def load_image_faiss(image_db_path: str) -> FAISS:
    """ì›¹í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ê¸°ë°˜ vectorDB (OCR / Image Caption ê²°ê³¼ê°€ ë²¡í„°í™”ë˜ì–´ ìˆìŒ)"""
    if not os.path.exists(image_db_path):
        raise FileNotFoundError(f"Image FAISS DB not found: {image_db_path}")

    return FAISS.load_local(
        image_db_path,
        embeddings,
        allow_dangerous_deserialization=True
    )

def load_api_faiss(api_db_path: str) -> FAISS:
    """API ì •ì˜ì„œ ì—‘ì…€ ê¸°ë°˜ vectorDB (API row ë‹¨ìœ„ ë²¡í„°í™”)"""
    if not os.path.exists(api_db_path):
        raise FileNotFoundError(f"API FAISS DB not found: {api_db_path}")

    return FAISS.load_local(
        api_db_path,
        embeddings,
        allow_dangerous_deserialization=True
    )

def load_text_faiss(text_db_path: str) -> FAISS:
    """API ì •ì˜ì„œ ì—‘ì…€ ê¸°ë°˜ vectorDB (text ë²¡í„°í™”)"""
    if not os.path.exists(text_db_path):
        raise FileNotFoundError(f"Text FAISS DB not found: {text_db_path}")

    return FAISS.load_local(
        text_db_path,
        embeddings,
        allow_dangerous_deserialization=True
    )

# =========================
# ë²¡í„° ê²€ìƒ‰ (ëª©ì  ë¶„ë¦¬)
# =========================
def search_image_context(image_faiss: FAISS, query: str, k: int = 5) -> List[Document]:
    """UI / í™”ë©´ / ì‚¬ìš©ì ë™ì‘ ê´€ì  ê²€ìƒ‰"""
    results=image_faiss.similarity_search_with_score(query, k=k)
    return [doc for doc, score in results]

def search_api_context(api_faiss: FAISS, query: str, k: int = 5) -> List[Document]:
    """API ê¸°ëŠ¥ / ìš”ì²­ / ì‘ë‹µ / í•„ë“œ ê´€ì  ê²€ìƒ‰"""
    results=api_faiss.similarity_search_with_score(query, k=k)
    return [doc for doc, score in results]

def search_text_context(text_faiss: FAISS, query: str, k: int = 5) -> List[Document]:
    """í™ˆí˜ì´ì§€ ê¸°ëŠ¥ ê²€ìƒ‰"""
    results=text_faiss.similarity_search_with_score(query, k=k)
    return [doc for doc, score in results]


# =========================
# ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ (image / api ë¶„ë¦¬)
# =========================
def build_context(img_docs: List[Document], api_docs: List[Document], text_docs: List[Document]) -> Dict[str, str]:
    """image / api / text ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜"""
    image_context = []
    api_context = []
    text_context = []

    if img_docs:
        for d in img_docs:
            image_context.append(d.page_content)
    if api_docs:
        for d in api_docs:
            api_context.append(d.page_content)
    if text_docs:
        for d in text_docs:
            text_context.append(
                f"[í˜ì´ì§€ëª…: {d.metadata.get('page','')}]\n"
                f"[ì„¹ì…˜: {d.metadata.get('section','')}]\n"
                f"{d.page_content}"
            )

    return {
        "image": "\n\n".join(image_context),
        "api": "\n\n".join(api_context),
        "text": "\n\n".join(text_context)
    }

# # =========================
# # 3ï¸âƒ£ usage_tool í…ŒìŠ¤íŠ¸ (usage_tool ì •ìƒì¶œë ¥ í…ŒìŠ¤íŠ¸ìš©, í•„ìš”ì‹œ ìƒëµ ê°€ëŠ¥)
# # =========================
# def test_usage_tool():
#     query = "ê²Œì‹œê¸€ì„ ì‘ì„±í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ë¼?"

#     result = usage_tool.invoke({
#         "query": query,
#         "img": IMAGE_FAISS_DIR,
#         "api": API_FAISS_DIR
#     })

#     print("\n====================")
#     print("ğŸ¤– AI ì‘ë‹µ ê²°ê³¼")
#     print("====================\n")
#     print(result)

# # =========================
# # main
# # =========================
#if __name__ == "__main__":      # Python ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ ì‘ì„±ëœ ì„¸ ê°œì˜ í•¨ìˆ˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ.
    # build_image_faiss()
    # build_api_faiss()
    #test_usage_tool()
    #build_text_faiss()
