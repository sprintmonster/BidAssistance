# main.py
import os
import uvicorn
from fastapi import FastAPI, HTTPException, Request, File, Form, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, validator, root_validator
from dotenv import load_dotenv
from pyngrok import ngrok
from langchain_core.messages import HumanMessage
from typing import Optional, Dict, Any, Union, List
import requests
from pathlib import Path
import PyPDF2
from datetime import datetime
import logging
import uuid
import json
from langchain_core.messages import ToolMessage
import tempfile

# ë¶„ë¦¬ëœ ê·¸ë˜í”„ ì•± import
from graph import graph_app

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==========================================
# TFT + RAG Pipeline ì´ˆê¸°í™”
# ==========================================

from BidAssitanceModel import BidRAGPipeline, extract_text_from_hwp, extract_text_from_hwpx, extract_text_from_pdf
from get_probability_from_model import ProbabilityPredictor
import re
import uuid
import os

TFT_MODEL_PATH = './results_transformer/best_model.pt'

def parsenumber(value: Any) -> Optional[float]:
    """
    ë‹¤ì–‘í•œ í˜•íƒœì˜ ìˆ«ì ë¬¸ìì—´ì„ floatë¡œ ë³€í™˜
    ì˜ˆ: "1,000,000ì›" -> 1000000.0
    """
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)

    s = str(value).strip()
    s = re.sub(r'[^0-9.\-]', '', s.replace(',', ''))
    try:
        return float(s)
    except:
        return None


# TFT ëª¨ë¸ ë¡œë“œ
try:
    tft_predictor = ProbabilityPredictor(model_path=TFT_MODEL_PATH)
    print("âœ… TFT ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    print("âš ï¸ TFT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", e)
    tft_predictor = None


class TFTPredictorAdapter:
    """RAG íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©í•  TFT ëª¨ë¸ ì–´ëŒ‘í„° - top_ranges ì§€ì›"""

    def __init__(self, predictor):
        self.predictor = predictor

    def predict(self, requirements: Dict[str, Any], retrieved_context: str = "") -> Dict[str, Any]:
        """ì…ì°° ìš”êµ¬ì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ TFT ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ - top_ranges í¬í•¨"""
        try:
            if not self.predictor:
                return {
                    "error": "Model not loaded",
                    "point_estimate": 0,
                    "confidence": "error",
                    "rationale": "TFT Model not loaded"
                }

            # ì…ë ¥ ë°ì´í„° íŒŒì‹±
            pr_range = parsenumber(requirements.get('expected_price_range')) or 0.0
            lower_rate = parsenumber(requirements.get('award_lower_rate')) or 0.0
            estimate = parsenumber(requirements.get('estimate_price')) or 0.0
            budget = parsenumber(requirements.get('budget')) or 0.0

            input_dict = {
                'ì˜ˆê°€ë²”ìœ„': pr_range,
                'ë‚™ì°°í•˜í•œìœ¨': lower_rate,
                'ì¶”ì •ê°€ê²©': estimate,
                'ê¸°ì´ˆê¸ˆì•¡': budget
            }

            # TFT ëª¨ë¸ë¡œ í™•ë¥  ë†’ì€ ìƒìœ„ 3ê°œ êµ¬ê°„ ì˜ˆì¸¡
            result = self.predictor.get_highest_probability_ranges(
                input_dict,
                bin_width=0.001,
                top_k=3
            )

            if result and result.get("top_ranges"):
                top_ranges = result["top_ranges"]
                return {
                    "currency": "KRW",
                    "point_estimate": float(top_ranges[0]["center"]),  # ê°€ì¥ í™•ë¥  ë†’ì€ êµ¬ê°„ì˜ ì¤‘ì‹¬ê°’
                    "predicted_min": float(result["statistics"]["q25"]),  # 25% ë¶„ìœ„ìˆ˜
                    "predicted_max": float(result["statistics"]["q75"]),  # 75% ë¶„ìœ„ìˆ˜
                    "confidence": "high",
                    "top_ranges": top_ranges,  # âœ… ìƒìœ„ í™•ë¥  êµ¬ê°„ë“¤
                    "statistics": result["statistics"],  # ì¶”ê°€ í†µê³„ ì •ë³´
                    "rationale": f"TFT Model - Top {len(top_ranges)} í™•ë¥  êµ¬ê°„ ë¶„ì„ ì™„ë£Œ",
                    "model_type": "QuantileTransformerRegressor"
                }
            else:
                return {
                    "error": "Prediction failed",
                    "point_estimate": 0,
                    "confidence": "low",
                    "rationale": "TFT ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ"
                }

        except Exception as e:
            print(f"âŒ TFT ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return {
                "error": str(e),
                "point_estimate": 0,
                "confidence": "error",
                "rationale": f"Prediction Failed: {str(e)}"
            }

# RAG Pipeline ìƒì„±
adapter = TFTPredictorAdapter(tft_predictor)

rag_pipeline = BidRAGPipeline(
    doc_dir="./rag_corpus",
    index_dir="./rag_index",
    award_predict_fn=adapter.predict
)

print("ğŸš€ RAG + TFT Pipeline Ready")

# =================================================================
# 1. Config & Setup
# =================================================================
class Config:
    NGROK_AUTH_TOKEN = os.getenv("NGROK_AUTH_TOKEN")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

    @classmethod
    def check(cls):
        if not cls.OPENAI_API_KEY:
            print("âš ï¸ Warning: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

Config.check()

# =================================================================
# 2. FastAPI App Setup
# =================================================================
app = FastAPI(
    title="LangGraph Chatbot API",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
    )

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# HTTP ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = datetime.now()
    logger.info(f"Request: {request.method} {request.url.path}")
    try:
        response = await call_next(request)
        duration = (datetime.now() - start_time).total_seconds()
        logger.info(f"Response: {request.method} {request.url.path} - {response.status_code} - {duration:.2f}s")
        return response
    except Exception as e:
        logger.error(f"Error: {e}", exc_info=True)
        raise

# ìš”ì²­ ë°ì´í„° ëª¨ë¸
class ChatRequest(BaseModel):
    type: str="choose query | notice_result | reprot"
    query: str="user question"
    payload: Optional[Union[Dict[str, Any], List[Dict[str, Any]],str]] = None
    thread_id: str = "default_session"  # ì„¸ì…˜ êµ¬ë¶„ì„ ìœ„í•œ ID

class AnalyzeRequest(BaseModel):
    text: Optional[str] = None
    file_url: Optional[str] = None  # íŒŒì¼ URL
    pdf_path: Optional[str] = None  # íŒŒì¼ ê²½ë¡œ
    
    @root_validator(pre=True)
    def check_at_least_one(cls, values):
        # ìµœì†Œ í•˜ë‚˜ì˜ ì…ë ¥ ì†ŒìŠ¤ ê²€ì¦
        if not any([values.get('text'), values.get('file_url'), values.get('pdf_path')]):
            raise ValueError('At least one input source required (text, file_url, or pdf_path)')
        return values

class ErrorResponse(BaseModel):
    error: str
    detail: str
    timestamp: str
    path: str

# HTTPException ì˜ˆì™¸ ì²˜ë¦¬
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=f"HTTP_{exc.status_code}",
            detail=exc.detail,
            timestamp=datetime.now().isoformat(),
            path=str(request.url.path)
        ).dict()
    )

# ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬
@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="INTERNAL_SERVER_ERROR",
            detail=str(exc),
            timestamp=datetime.now().isoformat(),
            path=str(request.url.path)
        ).dict()
    )

@app.get("/status_check")
def root():
    return {"status": "running", "message": "LangGraph API is active"}

@app.post("/analyze")
async def analyze(file: UploadFile = File(...),
                  thread_id: str = Form("default")
                  ):
    """ì…ì°°ê³µê³  ë¶„ì„ + TFT ì˜ˆì¸¡ + PDF ìƒì„± + Azure ì—…ë¡œë“œ"""
    try:
        # 1) ì—…ë¡œë“œ íŒŒì¼ ì´ë¦„ í™•ì¸
        filename = file.filename.lower()

        # 2) ì„ì‹œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            tmp_path = tmp.name
            tmp.write(await file.read())

        # 3) íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if filename.endswith(".pdf"):
            extracted_text = extract_text_from_pdf(tmp_path)

        elif filename.endswith(".hwp"):
            extracted_text = extract_text_from_hwp(tmp_path)
        
        elif filename.endswith(".hwpx"):
            extracted_text = extract_text_from_hwpx(tmp_path)
        else:
            os.remove(tmp_path)
            raise HTTPException(
                status_code=400,
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (pdf/hwp/hwpxë§Œ ê°€ëŠ¥)"
            )
        
        # 4) ì¶”ì¶œ ì‹¤íŒ¨ ì²´í¬
        if not extracted_text.strip():
            os.remove(tmp_path)
            raise HTTPException(
                status_code=400,
                detail="íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )
        
        # 1. RAG íŒŒì´í”„ë¼ì¸ ë¶„ì„ ìˆ˜í–‰
        result = rag_pipeline.analyze(
            extracted_text,
            thread_id=thread_id
        )

        report_md = result.get("report_markdown", "")
        prediction_result = result.get("prediction_result", {})
        os.remove(tmp_path)
        '''
        # 2. PDF ì €ì¥ í´ë” ì¤€ë¹„
        output_dir = "./output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        pdf_filename = f"report_{uuid.uuid4().hex[:6]}.pdf"
        pdf_path = os.path.join(output_dir, pdf_filename)
        
        # 3. PDF ìƒì„± ë° Azure ì—…ë¡œë“œ
        final_url = None
        try:
            if not report_md:
                raise ValueError("ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

            generate_pdf(report_md, pdf_path)
            full_pdf_path = os.path.abspath(pdf_path)

            final_url = upload_to_azure(full_pdf_path, pdf_filename)
        
        except Exception as e:
            print(f"âŒ PDF/Azure ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            #final_url = f"PDF ìƒì„± ì‹¤íŒ¨: {str(e)}"
        '''

        # 4. ì‘ë‹µ ë°˜í™˜
        return {
            #"extracted_requirements": result.get("requirements", {}),
            #"prediction": prediction_result,  # âœ… top_ranges í¬í•¨ë¨
            "report": report_md,
            #"pdf_link": final_url,
            "thread_id": thread_id
        }

    except Exception as e:
        print(f"âŒ /analyze ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    """
    LangGraphë¥¼ ì‹¤í–‰í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        if req.type == "query":
            content = req.query

        else:
            # payload ê¸°ë°˜ í›„ì²˜ë¦¬ ì…ë ¥
            content = json.dumps(
                {
                    "type": req.type,
                    "payload": req.payload
                },
                ensure_ascii=False
            )
        
        #ì§ˆë¬¸ í˜•íƒœê°€ ì•„ë‹Œë° ë‹´ê²¨ì˜¤ëŠ” ê°’ì´ ì—†ì„ ë•Œ
        if req.type != "query" and req.payload is None:
            raise HTTPException(status_code=400, detail="payload is required")

        # LangGraph ì…ë ¥ ë©”ì‹œì§€ ìƒì„±
        
        inputs = {"messages": [HumanMessage(content=content)]}
        config = {"configurable": {"thread_id": req.thread_id}}
        
        # ê·¸ë˜í”„ ì‹¤í–‰ (invokeëŠ” ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ async def ì•ˆì—ì„œëŠ” ì£¼ì˜ í•„ìš”)
        # LangGraphì˜ invoke()ëŠ” ìµœì¢… ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        final_state = await graph_app.ainvoke(inputs, config=config)
        
        # ë§ˆì§€ë§‰ ë©”ì‹œì§€(AI ë‹µë³€) ì¶”ì¶œ
        last_message = final_state["messages"][-1]
        final_text = last_message.content if last_message else ""

        # âœ… ì‘ë‹µ type ê²°ì • (ìš”ì²­ type(req.type) ë§ê³  "ê²°ê³¼" ê¸°ì¤€)
        resp_type = "chat"

        # í›„ì²˜ë¦¬ ìš”ì²­ì´ë©´ summaryë¡œ ê³ ì •
        if req.type in ("notice_result", "report"):
            resp_type = "summary"
        else:
            # toolì´ ë§ˆì§€ë§‰ì´ê±°ë‚˜ JSONì²˜ëŸ¼ ë³´ì´ë©´ searchë¡œ ë¶„ë¥˜
            if isinstance(last_message, ToolMessage):
                resp_type = "search"
            else:
                s = (final_text or "").strip()
                if s.startswith("{") and s.endswith("}"):
                    resp_type = "search"


        return {
            "type": resp_type,
            "response": final_text,
            "thread_id": req.thread_id
        }
        
    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/input_content")
async def input_content_endpoint(req: AnalyzeRequest):
    """
    íŒŒì¼ URL ë˜ëŠ” PDF ê²½ë¡œì—ì„œ íŒŒì¼ì„ ì½ì–´ ë¶„ì„í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    (í…ìŠ¤íŠ¸ëŠ” /chat ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
    """
    content = None
    source = None
    
    # íŒŒì¼ URLì—ì„œ ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬
    if req.file_url:
        try:
            response = requests.get(req.file_url, timeout=30)
            response.raise_for_status()
            content = response.text
            source = "file_url"
        except requests.exceptions.RequestException as e:
            raise HTTPException(status_code=400, detail=f"Failed to download file: {str(e)}")
    
    # PDF íŒŒì¼ ê²½ë¡œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    elif req.pdf_path:
        try:
            pdf_path = Path(req.pdf_path)
            if not pdf_path.exists():
                raise HTTPException(status_code=400, detail=f"PDF file not found: {req.pdf_path}")
            
            with open(pdf_path, 'rb') as pdf_file:
                pdf_reader = PyPDF2.PdfReader(pdf_file)
                content = ""
                for page in pdf_reader.pages:
                    content += page.extract_text()
            source = "pdf_path"
        except HTTPException:
            # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „íŒŒ
            raise
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Failed to read PDF: {str(e)}")
    
    # í…ìŠ¤íŠ¸ ì…ë ¥ (plain textëŠ” /chat ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© ê¶Œì¥)
    elif req.text:
        content = req.text
        source = "text"
    
    # LangGraphë¥¼ ì‹¤í–‰í•˜ì—¬ ë¶„ì„
    try:
        inputs = {"messages": [HumanMessage(content=str(content))]}
        # ê³ ìœ í•œ thread_id ìƒì„±
        thread_id = f"analyze_{uuid.uuid4().hex[:8]}"
        config = {"configurable": {"thread_id": thread_id}}
        
        final_state = await graph_app.ainvoke(inputs, config=config)
        last_message = final_state["messages"][-1]
        
        return {
            "source": source,
            "content_length": len(str(content)),
            "content_preview": str(content)[:200] + "..." if len(str(content)) > 200 else str(content),
            "response": last_message.content,
            "thread_id": thread_id,
            "status": "success"
        }
    except Exception as e:
        logger.error(f"Error in graph execution: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# =================================================================
# 3. Server Execution
# =================================================================
if __name__ == "__main__":
    # ngrok ì„¤ì • (ì™¸ë¶€ ì ‘ì† í•„ìš” ì‹œ)
    if Config.NGROK_AUTH_TOKEN:
        ngrok.set_auth_token(Config.NGROK_AUTH_TOKEN)
        public_url = ngrok.connect(8000)
        print(f"\nğŸŒ Public URL: {public_url.public_url}\n")
    else:
        print("\n[Info] ë¡œì»¬ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. (http://localhost:8000)\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
